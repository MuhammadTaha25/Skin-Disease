{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Skin Disease Model"
      ],
      "metadata": {
        "id": "1aQbaylsjcCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import all the Dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "hoIh2QFujTtc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yesshM6Rf9iq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_path = '/content/archive (16).zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "u7Ph-_LXjmCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set all the Constants\n"
      ],
      "metadata": {
        "id": "0H_N0yJ_jall"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 0.000001\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "IMAGE_SIZE =224\n",
        "default_image_size = tuple((IMAGE_SIZE, IMAGE_SIZE))\n",
        "image_size = 0\n",
        "data_dir = \"/content/skin-disease-datasaet/train_set\"\n",
        "CHANNELS=3\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "Q9K-rDA5gDB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing, Exploring & Partioning the Dataset\n",
        "\n",
        "## Function to Split Dataset\n",
        "\n",
        "\n",
        "Function to Split Dataset\n",
        "Dataset should be bifurcated into 3 subsets, namely:\n",
        "\n",
        "1. Training: Dataset to be used while training\n",
        "2. Validation: Dataset to be tested against while training\n",
        "3. Test: Dataset to be tested against after we trained a model"
      ],
      "metadata": {
        "id": "gSHjC47IjGMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "SEED = 123\n",
        "\n",
        "# Load full training dataset from train folder\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/skin-disease-datasaet/train_set\",\n",
        "    seed=SEED,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Load full test dataset from test folder\n",
        "full_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/skin-disease-datasaet/test_set\",\n",
        "    seed=SEED,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=1,  # Important for selecting exact number of images\n",
        "    shuffle=True   # Shuffle so we get random 20 images for test\n",
        ")\n",
        "\n",
        "# Flatten test dataset to individual images\n",
        "full_test_ds = full_test_ds.unbatch()\n",
        "\n",
        "# Take first 20 images for test\n",
        "test_ds = full_test_ds.take(20).batch(BATCH_SIZE)\n",
        "\n",
        "# Skip first 20 and use the rest as validation\n",
        "val_ds = full_test_ds.skip(20).batch(BATCH_SIZE)\n",
        "\n",
        "# Prefetch for performance\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "VezVG32SgHpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd60cb9-a793-4609-e0b0-3974448cd588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 924 files belonging to 8 classes.\n",
            "Found 233 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and Partitioning the Dataset\n",
        "\n",
        "We create a Tensorflow Dataset Object and directly read it from the directory using image_dataset_from_directory and then split it using the function we created above"
      ],
      "metadata": {
        "id": "3gYQnwhKi91w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  seed=123,\n",
        "  image_size=default_image_size,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "vG4p6XFdgKOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3681aacb-c7c2-4b58-d6f9-e2b2ad288e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 924 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the Available Classes\n"
      ],
      "metadata": {
        "id": "_czOf5lTiyEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_names = dataset.class_names\n",
        "n_classes = len(class_names)\n",
        "print(n_classes, class_names)"
      ],
      "metadata": {
        "id": "01LJ319_gMS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ec4ef0-ee05-422f-cfdc-ba75112343d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 ['BA- cellulitis', 'BA-impetigo', 'FU-athlete-foot', 'FU-nail-fungus', 'FU-ringworm', 'PA-cutaneous-larva-migrans', 'VI-chickenpox', 'VI-shingles']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying Some Sample Images\n"
      ],
      "metadata": {
        "id": "wOBoTDkuivpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "wfdtnvn5gOQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Batch Size\n"
      ],
      "metadata": {
        "id": "L69ZdB8sissy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "XfZrVXAOgQjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cache, Shuffle, and Prefetch the Dataset\n"
      ],
      "metadata": {
        "id": "entRGEUjip2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0M8NxcotgSpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds"
      ],
      "metadata": {
        "id": "ITP5CchFloPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model\n"
      ],
      "metadata": {
        "id": "IvuKRzNOilVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Layer for Resizing and Normalization\n"
      ],
      "metadata": {
        "id": "aewmQP0miisP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model."
      ],
      "metadata": {
        "id": "aBCUJog8igh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "  layers.Rescaling(1./255),\n",
        "])"
      ],
      "metadata": {
        "id": "PqiIuhYhgUwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n"
      ],
      "metadata": {
        "id": "eZWxQUFRiZ5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation is needed when we have less data, this boosts the accuracy of our model by augmenting the data."
      ],
      "metadata": {
        "id": "4eeJaViXidMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomFlip(\"vertical\") ,   # top-bottom flip\n",
        "    # layers.RandomTranslation(0.1, 0.1),  # 10% horizontal & vertical shift\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomBrightness(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "UJv9YAH8gWrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking what is the expected dimension order for channel\n"
      ],
      "metadata": {
        "id": "WRt3lS5RiWw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "batch_input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    input_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "    batch_input_shape = (BATCH_SIZE, CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "    chanDim = 1"
      ],
      "metadata": {
        "id": "Ub-gURHEgYqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n"
      ],
      "metadata": {
        "id": "PA7ArhQ1iQYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation.\n",
        "\n"
      ],
      "metadata": {
        "id": "PusB4K4giTo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    # layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    # layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.build(input_shape=batch_input_shape)"
      ],
      "metadata": {
        "id": "rY0BubzjgcFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summary\n"
      ],
      "metadata": {
        "id": "Ov3WT-faiMok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "C9GXVq4IggsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling the Model"
      ],
      "metadata": {
        "id": "-PHD3UKPiA7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric"
      ],
      "metadata": {
        "id": "-Cf_yhqciJen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "8VCByS0dgio6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Network\n"
      ],
      "metadata": {
        "id": "MKxW8pE8h9pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# history = model.fit(\n",
        "#     train_ds,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     validation_data=val_ds,\n",
        "#     verbose=1,\n",
        "#     epochs=20,\n",
        "# )"
      ],
      "metadata": {
        "id": "q4D4k8Hu2DKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Callback for saving best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"best_model.h5\",                # file name for saving best model\n",
        "    monitor=\"val_accuracy\",         # metric to monitor\n",
        "    mode=\"max\",                     # because higher accuracy is better\n",
        "    save_best_only=True,            # only save the best one\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=47,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "id": "41UuIGEZWWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model\n"
      ],
      "metadata": {
        "id": "3A4JPtcOhnJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {round(scores[1],4)*100}%\")"
      ],
      "metadata": {
        "id": "TDMzS_BVhlw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Accuracy and Loss Curves\n"
      ],
      "metadata": {
        "id": "sdCS9T1fhaA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(history.history['accuracy']))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jp_iytj3gst2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model\n"
      ],
      "metadata": {
        "id": "h1Cx6ifShDWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We append the model to the list of models as a new version\n",
        "\n"
      ],
      "metadata": {
        "id": "cfA-D-CjhLQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # import os\n",
        "# # model_version = max([int(i) for i in (os.listdir(\"../models\")+[0])]) + 1\n",
        "# model.save(f\"/content/modle.h5\")"
      ],
      "metadata": {
        "id": "MzLujQg7gu9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for Inference\n"
      ],
      "metadata": {
        "id": "KBDjtPt7hULl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(f\"/content/modle.h5\")\n",
        "# def predict(model, img):\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "#     img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "#     predictions = model.predict(img_array)\n",
        "\n",
        "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
        "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "#     return predicted_class, confidence"
      ],
      "metadata": {
        "id": "XxhqTox5g5so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Inference Data"
      ],
      "metadata": {
        "id": "nq1xxUN8g-4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(15, 15))\n",
        "# for images, labels in test_ds.take(1):\n",
        "#     for i in range(9):\n",
        "#         ax = plt.subplot(3, 3, i + 1)\n",
        "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#         predicted_class, confidence = predict(model, images[i].numpy())\n",
        "\n",
        "#         actual_class = class_names[labels[i]]\n",
        "#         plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "#         plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "KP2TBb41g8zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import ResNet50\n",
        "# from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# # Pretrained ResNet50 base\n",
        "# # inputs = tf.keras.Input(shape=(224,224,3))\n",
        "# # x = data_augmentation(inputs)\n",
        "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# # Freeze base layers\n",
        "# base_model.trainable = False\n",
        "\n",
        "# # Add custom classifier\n",
        "# x = GlobalAveragePooling2D()(base_model.output)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "# x = Dropout(0.4)(x)\n",
        "# output = Dense(n_classes, activation='softmax')(x) # Use n_classes instead of hardcoded 8\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # Change loss function\n",
        "#               metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JUCwHZYz5bUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(\n",
        "#     train_ds,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     validation_data=val_ds,\n",
        "#     verbose=1,\n",
        "#     epochs=8,\n",
        "# )"
      ],
      "metadata": {
        "id": "-52WCTIV5lAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs_range = range(len(history.history['accuracy']))\n",
        "\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(epochs_range, loss, label='Training Loss')\n",
        "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "# plt.legend(loc='upper right')\n",
        "# plt.title('Training and Validation Loss')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "-N1T46HF5seW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict(model, img):\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "#     img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "#     predictions = model.predict(img_array)\n",
        "\n",
        "#     predicted_class = class_names[np.argmax(predictions[0])]\n",
        "#     confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "#     return predicted_class, confidence"
      ],
      "metadata": {
        "id": "g8fuBmwc6zOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"[INFO] Calculating model accuracy\")\n",
        "# scores = model.evaluate(test_ds)\n",
        "# print(f\"Test Accuracy: {round(scores[1],4)*100}%\")"
      ],
      "metadata": {
        "id": "g7E1cc1DQv-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Assuming test_ds is created from test_set folder like:\n",
        "# # test_ds = image_dataset_from_directory(\"dataset/test_set\", ...)\n",
        "\n",
        "# # You can hardcode the folder name here since you're looping over test_ds\n",
        "# origin_folder = \"test_set\"\n",
        "\n",
        "# plt.figure(figsize=(15, 15))\n",
        "# for images, labels in test_ds.take(1):\n",
        "#     for i in range(9):\n",
        "#         ax = plt.subplot(3, 3, i + 1)\n",
        "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "#         # Assuming predict returns: (predicted_class: str, confidence: float)\n",
        "#         predicted_class, _ = predict(model, images[i].numpy())\n",
        "\n",
        "#         actual_class = class_names[labels[i]]\n",
        "#         plt.title(f\"Folder: {origin_folder}\\nActual: {actual_class}\\nPredicted: {predicted_class}\")\n",
        "#         plt.axis(\"off\")\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "7iu7VFK-QmU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(f\"/content/modle.h5\")\n"
      ],
      "metadata": {
        "id": "VS9BJU7X604h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}